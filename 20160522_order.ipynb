{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dateutil.parser import parse as dateutil_parse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler as skStandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.cross_validation import train_test_split,cross_val_score\n",
    "\n",
    "PATH = 'season_1/'\n",
    "CLEAN_PATH = PATH+'clean/'\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class myStandardScaler(skStandardScaler):\n",
    "    '''\n",
    "    Only use fit_transform and tranform, specific for dealing with pd.DataFrame.\n",
    "    Only scale the numerical features.\n",
    "    '''\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        Xnumerical = X[X.columns[X.dtypes != bool]]\n",
    "        Xdummy = X[X.columns[X.dtypes == bool]]\n",
    "        scaledXnumerical = super(myStandardScaler, self).fit_transform(Xnumerical)\n",
    "        Xnumerical = pd.DataFrame(scaledXnumerical, index=Xnumerical.index, columns=Xnumerical.columns)\n",
    "        return pd.concat([Xnumerical, Xdummy], axis=1)\n",
    "\n",
    "    def transform(self, X):\n",
    "        Xnumerical = X[X.columns[X.dtypes != bool]]\n",
    "        Xdummy = X[X.columns[X.dtypes == bool]]\n",
    "        scaledXnumerical = super(myStandardScaler, self).transform(Xnumerical)\n",
    "        Xnumerical = pd.DataFrame(scaledXnumerical, index=Xnumerical.index, columns=Xnumerical.columns)\n",
    "        return pd.concat([Xnumerical, Xdummy], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_map = pd.read_csv(CLEAN_PATH+'cluster_map.csv',index_col=0)\n",
    "poi = pd.read_csv(CLEAN_PATH+'poi.csv',index_col=0)\n",
    "train_order = pd.read_pickle(CLEAN_PATH+'train_order.pickle')\n",
    "test_order = pd.read_pickle(CLEAN_PATH+'test_order.pickle')\n",
    "train_traffic = pd.read_pickle(CLEAN_PATH+'train_traffic.pickle')\n",
    "test_traffic = pd.read_pickle(CLEAN_PATH+'test_traffic.pickle')\n",
    "train_weather = pd.read_pickle(CLEAN_PATH+'train_weather.pickle')\n",
    "test_weather = pd.read_pickle(CLEAN_PATH+'test_weather.pickle')\n",
    "test_target = pd.read_csv(CLEAN_PATH+'test_target.csv',index_col=0,parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timeslot</th>\n",
       "      <th>datetimeslot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-22</th>\n",
       "      <td>46</td>\n",
       "      <td>20160122046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-22</th>\n",
       "      <td>58</td>\n",
       "      <td>20160122058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-22</th>\n",
       "      <td>70</td>\n",
       "      <td>20160122070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-22</th>\n",
       "      <td>82</td>\n",
       "      <td>20160122082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-22</th>\n",
       "      <td>94</td>\n",
       "      <td>20160122094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timeslot  datetimeslot\n",
       "datetime                          \n",
       "2016-01-22        46   20160122046\n",
       "2016-01-22        58   20160122058\n",
       "2016-01-22        70   20160122070\n",
       "2016-01-22        82   20160122082\n",
       "2016-01-22        94   20160122094"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target['datetimeslot'] = np.array(test_target.index.map(lambda x: x.year*10000+x.month*100+x.day),dtype=np.int64)*1000+test_target['timeslot'].values\n",
    "test_target.to_csv(CLEAN_PATH+'test_target.csv')\n",
    "test_target = pd.read_csv(CLEAN_PATH+'test_target.csv',index_col=0,parse_dates=True)\n",
    "test_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_order_index = pd.Series(range(len(train_order)),index=train_order['Time'])\n",
    "test_order_index = pd.Series(range(len(test_order)),index=test_order['Time'])\n",
    "train_traffic_index = pd.Series(range(len(train_traffic)),index=train_traffic['datetime'])\n",
    "test_traffic_index = pd.Series(range(len(test_traffic)),index=test_traffic['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_order(order):\n",
    "    def pclass(p):\n",
    "        class_set = range(5,20,5)+range(20,100,10)+range(100,501,100)\n",
    "        idx_set = [p>cls for cls in class_set]\n",
    "        return idx_set.index(False) if sum(idx_set)!=len(idx_set) else len(idx_set)\n",
    "    order['timeslot'] = order['Time'].map(lambda x: (x.hour*60+x.minute)/10+1)\n",
    "    order['datetimeslot'] = order['Time'].map(lambda x: x.year*10000+x.month*100+x.day)*1000+order['timeslot']\n",
    "    order['pclass'] = order['Price'].map(lambda x: pclass(x))\n",
    "    order = pd.concat([order,pd.get_dummies(order['pclass'],'pclass').applymap(lambda x: {1.0: True, 0.0: False}[x])],axis=1)\n",
    "    return order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_order = process_order(test_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_order = process_order(train_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_group(group):\n",
    "    res = pd.Series()\n",
    "    res['request'] = group['request'].count()\n",
    "    res['answer'] = group['request'].sum()\n",
    "    res['price_avg'] = group['Price'].mean()\n",
    "    pclass_cols = filter(lambda x: x[:7]=='pclass_',group.columns)\n",
    "    pclass_values = group[pclass_cols].sum()\n",
    "    res = pd.concat([res,pclass_values])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp = train_order[train_order['start_district_hash']=='b05379ac3f9b7d99370d443cfd5dcc28']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp_group = tmp.groupby('datetimeslot').apply(lambda g: map_group(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test_order[test_order['start_district_hash']=='b05379ac3f9b7d99370d443cfd5dcc28']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_tmp = test_order[test_order['start_district_hash']=='b05379ac3f9b7d99370d443cfd5dcc28'].groupby('datetimeslot').apply(lambda g: map_group(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_test_order(order, dts):\n",
    "    '''\n",
    "    This funciton will not consider the first 3 time slot, for all the days. \n",
    "    It could be change when test data set changes.\n",
    "    '''\n",
    "    timeslot = pd.get_dummies(dts.map(lambda x: int(x%1000)),'timeslot')\n",
    "    timeslot = pd.DataFrame(timeslot, columns=['timeslot_'+str(i+1) for i in range(144)]).fillna(0)\n",
    "    timeslot.index = dts\n",
    "    timeslot = timeslot.applymap(lambda x: {1.0: True, 0.0: False}[x])\n",
    "    train = pd.concat([order.ix[dts-1].rename(columns=lambda x: '1_'+x,index=lambda x: x+1),\n",
    "                       order.ix[dts-2].rename(columns=lambda x: '2_'+x,index=lambda x: x+2),\n",
    "                       order.ix[dts-3].rename(columns=lambda x: '3_'+x,index=lambda x: x+3),\n",
    "                       timeslot], axis=1)\n",
    "    train = train.dropna()\n",
    "    test = (order['request'].ix[train.index]-order['answer'].ix[train.index])\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_testX, sample_testY = train_test_order(test_tmp, test_target['datetimeslot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_trainX, sample_trainY = train_test_order(tmp_group, tmp_group.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_scaler = myStandardScaler()\n",
    "sample_trainX = sample_scaler.fit_transform(sample_trainX)\n",
    "sample_testX = sample_scaler.transform(sample_testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2961, 204)\n",
      "(43, 204)\n",
      "(2961L,)\n",
      "(43L,)\n"
     ]
    }
   ],
   "source": [
    "print sample_trainX.shape\n",
    "print sample_testX.shape\n",
    "print sample_trainY.shape\n",
    "print sample_testY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98083052364416212"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr.fit(sample_trainX,sample_trainY)\n",
    "rfr.score(sample_trainX,sample_trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(target, predict):\n",
    "    return ((target-predict).abs()/target).replace(np.inf,0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4581520586868448"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = pd.Series(rfr.predict(sample_trainX),index=sample_trainY.index)\n",
    "evaluate(sample_trainY,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.482533949623496"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = pd.Series(np.floor(rfr.predict(sample_trainX)),index=sample_trainY.index)\n",
    "# prediction[prediction<10]=0\n",
    "evaluate(sample_trainY,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5388705039514087"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(sample_trainY,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(50, max_depth=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98192688610110135"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr.fit(sample_trainX,sample_trainY)\n",
    "rfr.score(sample_trainX,sample_trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3301811924264464"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = pd.Series(np.floor(rfr.predict(sample_trainX)),index=sample_trainY.index)\n",
    "# prediction[prediction<3]=0\n",
    "evaluate(sample_trainY,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(50, max_depth=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.83192855  0.83665273  0.81880207]\n",
      "0.829127786867\n",
      "0.00755180849321\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(RandomForestRegressor(50, max_depth=None), sample_trainX, sample_trainY)\n",
    "print scores\n",
    "print np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.83232479  0.84234057  0.82456352]\n",
      "0.833076292241\n",
      "0.00727687787112\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(RandomForestRegressor(100, max_depth=None), sample_trainX, sample_trainY)\n",
    "print scores\n",
    "print np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.84480065  0.83339436  0.81948089]\n",
      "0.832558634403\n",
      "0.0103536293373\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(RandomForestRegressor(100, max_depth=15), sample_trainX, sample_trainY)\n",
    "print scores\n",
    "print np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.84230125  0.84026807  0.82606753]\n",
      "0.836212283281\n",
      "0.00722128827981\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(RandomForestRegressor(100, max_depth=12), sample_trainX, sample_trainY)\n",
    "print scores\n",
    "print np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.82900214  0.83565789  0.82290252]\n",
      "0.829187520419\n",
      "0.00520900793899\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(RandomForestRegressor(100, max_depth=10), sample_trainX, sample_trainY)\n",
    "print scores\n",
    "print np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.84919958  0.83410134  0.80653142]\n",
      "0.82994411611\n",
      "0.0176654990323\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 100}\n",
    "scores = cross_val_score(GradientBoostingRegressor(**params), sample_trainX, sample_trainY)\n",
    "print scores\n",
    "print np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.85834383  0.84526779  0.807821  ]\n",
      "0.837144205245\n",
      "0.0214107980611\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 200}\n",
    "scores = cross_val_score(GradientBoostingRegressor(**params), sample_trainX, sample_trainY)\n",
    "print scores\n",
    "print np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.86356984  0.84781064  0.80441386]\n",
      "0.838598112194\n",
      "0.0250134664899\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 300}\n",
    "scores = cross_val_score(GradientBoostingRegressor(**params), sample_trainX, sample_trainY)\n",
    "print scores\n",
    "print np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.86747855  0.84982819  0.80352634]\n",
      "0.840277693026\n",
      "0.0269676380948\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 500}\n",
    "scores = cross_val_score(GradientBoostingRegressor(**params), sample_trainX, sample_trainY)\n",
    "print scores\n",
    "print np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.86641821  0.84908533  0.80368104]\n",
      "0.839728193757\n",
      "0.0264531661697\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 666}\n",
    "scores = cross_val_score(GradientBoostingRegressor(**params), sample_trainX, sample_trainY)\n",
    "print scores\n",
    "print np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.86590738  0.85088148  0.80008195]\n",
      "0.838956933151\n",
      "0.0281649065607\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 600}\n",
    "scores = cross_val_score(GradientBoostingRegressor(**params), sample_trainX, sample_trainY)\n",
    "print scores\n",
    "print np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.87208529  0.85081425  0.81085309]\n",
      "0.844584207304\n",
      "0.0253831395665\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 600, 'max_depth':4}\n",
    "scores = cross_val_score(GradientBoostingRegressor(**params), sample_trainX, sample_trainY)\n",
    "print scores\n",
    "print np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.86829028  0.85028311  0.80984489]\n",
      "0.842806092893\n",
      "0.0244389741667\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 300, 'max_depth':4}\n",
    "scores = cross_val_score(GradientBoostingRegressor(**params), sample_trainX, sample_trainY)\n",
    "print scores\n",
    "print np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.86958425  0.84880533  0.8103415 ]\n",
      "0.842910359575\n",
      "0.0245423296572\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 200, 'max_depth':4}\n",
    "scores = cross_val_score(GradientBoostingRegressor(**params), sample_trainX, sample_trainY)\n",
    "print scores\n",
    "print np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.85692664  0.84002017  0.78111598]\n",
      "0.826020931105\n",
      "0.0324940843419\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 200, 'max_depth':5}\n",
    "scores = cross_val_score(GradientBoostingRegressor(**params), sample_trainX, sample_trainY)\n",
    "print scores\n",
    "print np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.87746777  0.85067103  0.81381337]\n",
      "0.847317391685\n",
      "0.0260947728903\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 700, 'max_depth':4}\n",
    "scores = cross_val_score(GradientBoostingRegressor(**params), sample_trainX, sample_trainY)\n",
    "print scores\n",
    "print np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.87404269  0.85084484  0.80878474]\n",
      "0.844557423996\n",
      "0.0270098600407\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 1000, 'max_depth':4}\n",
    "scores = cross_val_score(GradientBoostingRegressor(**params), sample_trainX, sample_trainY)\n",
    "print scores\n",
    "print np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.87525401  0.85203513  0.81231287]\n",
      "0.846533999411\n",
      "0.0259883756135\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 888, 'max_depth':4}\n",
    "scores = cross_val_score(GradientBoostingRegressor(**params), sample_trainX, sample_trainY)\n",
    "print scores\n",
    "print np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.87354901  0.85247506  0.80706674]\n",
      "0.844363602576\n",
      "0.027740701252\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 600, 'max_depth':2}\n",
    "scores = cross_val_score(GradientBoostingRegressor(**params), sample_trainX, sample_trainY)\n",
    "print scores\n",
    "print np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.8752715   0.85331158  0.81066214]\n",
      "0.846415073692\n",
      "0.0268236657135\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 700, 'max_depth':2}\n",
    "scores = cross_val_score(GradientBoostingRegressor(**params), sample_trainX, sample_trainY)\n",
    "print scores\n",
    "print np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.87543448  0.85565737  0.8079698 ]\n",
      "0.846353880718\n",
      "0.0283170974111\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 888, 'max_depth':2}\n",
    "scores = cross_val_score(GradientBoostingRegressor(**params), sample_trainX, sample_trainY)\n",
    "print scores\n",
    "print np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.87542978  0.85562066  0.80884644]\n",
      "0.846632296444\n",
      "0.0279156865447\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 1000, 'max_depth':2}\n",
    "scores = cross_val_score(GradientBoostingRegressor(**params), sample_trainX, sample_trainY)\n",
    "print scores\n",
    "print np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.86786678  0.85086573  0.8031216 ]\n",
      "0.840618037631\n",
      "0.027407371921\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 1000, 'max_depth':3}\n",
    "scores = cross_val_score(GradientBoostingRegressor(**params), sample_trainX, sample_trainY)\n",
    "print scores\n",
    "print np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.86450854  0.84279917  0.85309296]\n",
      "0.853466892334\n",
      "0.00886675745556\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 888, 'max_depth':1}\n",
    "scores = cross_val_score(GradientBoostingRegressor(**params), sample_trainX, sample_trainY)\n",
    "print scores\n",
    "print np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.10925884  0.02875245  0.53539137]\n",
      "0.224467551866\n",
      "0.22229939982\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 888}\n",
    "scores = cross_val_score(AdaBoostRegressor(**params), sample_trainX, sample_trainY)\n",
    "print scores\n",
    "print np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.13549915  0.0656864   0.5553354 ]\n",
      "0.252173650873\n",
      "0.216254079293\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 777}\n",
    "scores = cross_val_score(AdaBoostRegressor(**params), sample_trainX, sample_trainY)\n",
    "print scores\n",
    "print np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.86727646  0.84397538  0.85336329]\n",
      "0.854871711193\n",
      "0.00957223340941\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 1000, 'max_depth':1}\n",
    "scores = cross_val_score(GradientBoostingRegressor(**params), sample_trainX, sample_trainY)\n",
    "print scores\n",
    "print np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.87029286  0.84592558  0.85564097]\n",
      "0.857286469614\n",
      "0.0100157163159\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 1200, 'max_depth':1}\n",
    "scores = cross_val_score(GradientBoostingRegressor(**params), sample_trainX, sample_trainY)\n",
    "print scores\n",
    "print np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.87317326  0.84591354  0.85569217]\n",
      "0.858259657546\n",
      "0.0112758449\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 1400, 'max_depth':1}\n",
    "scores = cross_val_score(GradientBoostingRegressor(**params), sample_trainX, sample_trainY)\n",
    "print scores\n",
    "print np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.87579618  0.84787489  0.85608119]\n",
      "0.859917421588\n",
      "0.0117171420647\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 1600, 'max_depth':1}\n",
    "scores = cross_val_score(GradientBoostingRegressor(**params), sample_trainX, sample_trainY)\n",
    "print scores\n",
    "print np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.87795925  0.84698918  0.85831164]\n",
      "0.861086693785\n",
      "0.0127948432795\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 1800, 'max_depth':1}\n",
    "scores = cross_val_score(GradientBoostingRegressor(**params), sample_trainX, sample_trainY)\n",
    "print scores\n",
    "print np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.87973784  0.84722323  0.85729653]\n",
      "0.861419197126\n",
      "0.0135903709951\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 2000, 'max_depth':1}\n",
    "scores = cross_val_score(GradientBoostingRegressor(**params), sample_trainX, sample_trainY)\n",
    "print scores\n",
    "print np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.88126799  0.84783497  0.85781834]\n",
      "0.862307101227\n",
      "0.014013167848\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 2200, 'max_depth':1}\n",
    "scores = cross_val_score(GradientBoostingRegressor(**params), sample_trainX, sample_trainY)\n",
    "print scores\n",
    "print np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.8825581   0.84846721  0.85930876]\n",
      "0.86344469058\n",
      "0.0142215036666\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 2400, 'max_depth':1}\n",
    "scores = cross_val_score(GradientBoostingRegressor(**params), sample_trainX, sample_trainY)\n",
    "print scores\n",
    "print np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.88870327  0.84988769  0.86230754]\n",
      "0.866966167533\n",
      "0.0161851688886\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 5000, 'max_depth':1}\n",
    "scores = cross_val_score(GradientBoostingRegressor(**params), sample_trainX, sample_trainY)\n",
    "print scores\n",
    "print np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9533831068471843"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'n_estimators': 3000, 'max_depth':1}\n",
    "gbr = GradientBoostingRegressor(**params).fit(sample_trainX,sample_trainY)\n",
    "gbr.score(sample_trainX,sample_trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94257934298836632"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'n_estimators': 1600, 'max_depth':1}\n",
    "gbr = GradientBoostingRegressor(**params).fit(sample_trainX,sample_trainY)\n",
    "gbr.score(sample_trainX,sample_trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8209407312872649"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'n_estimators': 1600, 'max_depth':1}\n",
    "gbr = GradientBoostingRegressor(**params).fit(sample_trainX,sample_trainY)\n",
    "gbr.score(sample_trainX,sample_trainY)\n",
    "prediction = pd.Series(np.floor(gbr.predict(sample_trainX)),index=sample_trainY.index)\n",
    "prediction[prediction<1]=0\n",
    "evaluate(sample_trainY,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.949781305332\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8032686794685913"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'n_estimators': 2400, 'max_depth':1}\n",
    "gbr = GradientBoostingRegressor(**params).fit(sample_trainX,sample_trainY)\n",
    "print gbr.score(sample_trainX,sample_trainY)\n",
    "prediction = pd.Series(np.floor(gbr.predict(sample_trainX)),index=sample_trainY.index)\n",
    "prediction[prediction<1]=0\n",
    "evaluate(sample_trainY,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.953383106847\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8006455656425373"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'n_estimators': 3000, 'max_depth':1}\n",
    "gbr = GradientBoostingRegressor(**params).fit(sample_trainX,sample_trainY)\n",
    "print gbr.score(sample_trainX,sample_trainY)\n",
    "prediction = pd.Series(np.floor(gbr.predict(sample_trainX)),index=sample_trainY.index)\n",
    "prediction[prediction<1]=0\n",
    "evaluate(sample_trainY,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.997025445715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4097701965628836"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'n_estimators': 3000, 'max_depth':2}\n",
    "gbr = GradientBoostingRegressor(**params).fit(sample_trainX,sample_trainY)\n",
    "print gbr.score(sample_trainX,sample_trainY)\n",
    "prediction = pd.Series(np.floor(gbr.predict(sample_trainX)),index=sample_trainY.index)\n",
    "prediction[prediction<1]=0\n",
    "evaluate(sample_trainY,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.994189976054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4917444061553089"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'n_estimators': 2000, 'max_depth':2}\n",
    "gbr = GradientBoostingRegressor(**params).fit(sample_trainX,sample_trainY)\n",
    "print gbr.score(sample_trainX,sample_trainY)\n",
    "prediction = pd.Series(np.floor(gbr.predict(sample_trainX)),index=sample_trainY.index)\n",
    "prediction[prediction<1]=0\n",
    "evaluate(sample_trainY,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.985239505045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5741488088999931"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'n_estimators': 1000, 'max_depth':2}\n",
    "gbr = GradientBoostingRegressor(**params).fit(sample_trainX,sample_trainY)\n",
    "print gbr.score(sample_trainX,sample_trainY)\n",
    "prediction = pd.Series(np.floor(gbr.predict(sample_trainX)),index=sample_trainY.index)\n",
    "prediction[prediction<1]=0\n",
    "evaluate(sample_trainY,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.996728555719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.40699437687917683"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'n_estimators': 1000, 'max_depth':3}\n",
    "gbr = GradientBoostingRegressor(**params).fit(sample_trainX,sample_trainY)\n",
    "print gbr.score(sample_trainX,sample_trainY)\n",
    "prediction = pd.Series(np.floor(gbr.predict(sample_trainX)),index=sample_trainY.index)\n",
    "prediction[prediction<1]=0\n",
    "evaluate(sample_trainY,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.988829646961\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5260184266078598"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'n_estimators': 500, 'max_depth':3}\n",
    "gbr = GradientBoostingRegressor(**params).fit(sample_trainX,sample_trainY)\n",
    "print gbr.score(sample_trainX,sample_trainY)\n",
    "prediction = pd.Series(np.floor(gbr.predict(sample_trainX)),index=sample_trainY.index)\n",
    "prediction[prediction<1]=0\n",
    "evaluate(sample_trainY,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.992900930099\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.48519406829139844"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'n_estimators': 666, 'max_depth':3}\n",
    "gbr = GradientBoostingRegressor(**params).fit(sample_trainX,sample_trainY)\n",
    "print gbr.score(sample_trainX,sample_trainY)\n",
    "prediction = pd.Series(np.floor(gbr.predict(sample_trainX)),index=sample_trainY.index)\n",
    "prediction[prediction<1]=0\n",
    "evaluate(sample_trainY,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.992868356957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4566300980020484"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'n_estimators': 333, 'max_depth':4}\n",
    "gbr = GradientBoostingRegressor(**params).fit(sample_trainX,sample_trainY)\n",
    "print gbr.score(sample_trainX,sample_trainY)\n",
    "prediction = pd.Series(np.floor(gbr.predict(sample_trainX)),index=sample_trainY.index)\n",
    "prediction[prediction<1]=0\n",
    "evaluate(sample_trainY,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.998262600445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.45444835015029017"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'n_estimators': 700, 'max_depth':4}\n",
    "gbr = GradientBoostingRegressor(**params).fit(sample_trainX,sample_trainY)\n",
    "print gbr.score(sample_trainX,sample_trainY)\n",
    "prediction = pd.Series(np.floor(gbr.predict(sample_trainX)),index=sample_trainY.index)\n",
    "prediction[prediction<3]=0\n",
    "evaluate(sample_trainY,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(sample_trainX,sample_trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.998931044445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9628558854962641"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'n_estimators': 700, 'max_depth':4}\n",
    "gbr = GradientBoostingRegressor(**params).fit(trainX,trainY)\n",
    "print gbr.score(trainX,trainY)\n",
    "prediction = pd.Series(np.floor(gbr.predict(testX)),index=testY.index)\n",
    "# prediction[prediction<3]=0\n",
    "evaluate(testY,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.103515434427381"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[prediction<1]=0\n",
    "evaluate(testY,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.995240496178\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.014553732914814"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'n_estimators': 666, 'max_depth':3}\n",
    "gbr = GradientBoostingRegressor(**params).fit(trainX,trainY)\n",
    "print gbr.score(trainX,trainY)\n",
    "prediction = pd.Series(np.floor(gbr.predict(testX)),index=testY.index)\n",
    "# prediction[prediction<3]=0\n",
    "evaluate(testY,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.995240496178\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.1812284668022275"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'n_estimators': 666, 'max_depth':3}\n",
    "gbr = GradientBoostingRegressor(**params).fit(trainX,trainY)\n",
    "print gbr.score(trainX,trainY)\n",
    "prediction = pd.Series(np.floor(gbr.predict(testX)),index=testY.index)\n",
    "prediction[prediction<3]=0\n",
    "evaluate(testY,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.995240496178\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9685886082386577"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'n_estimators': 666, 'max_depth':3}\n",
    "gbr = GradientBoostingRegressor(**params).fit(trainX,trainY)\n",
    "print gbr.score(trainX,trainY)\n",
    "prediction = pd.Series(np.floor(gbr.predict(testX)),index=testY.index)\n",
    "prediction[prediction<200]=0\n",
    "evaluate(testY,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9888775835229554"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[prediction<300]=0\n",
    "evaluate(testY,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.995240496178\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9298437725185077"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'n_estimators': 666, 'max_depth':3}\n",
    "gbr = GradientBoostingRegressor(**params).fit(trainX,trainY)\n",
    "print gbr.score(trainX,trainY)\n",
    "prediction = pd.Series(np.floor(gbr.predict(testX)),index=testY.index)\n",
    "prediction[prediction<100]=0\n",
    "evaluate(testY,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.978959514333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9141660397864777"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# params = {'n_estimators': 100, 'max_depth':12}\n",
    "gbr = RandomForestRegressor(100, max_depth=12).fit(trainX,trainY)\n",
    "print gbr.score(trainX,trainY)\n",
    "prediction = pd.Series(np.floor(gbr.predict(testX)),index=testY.index)\n",
    "# prediction[prediction<100]=0\n",
    "evaluate(testY,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.977740712774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.1239701280277377"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# params = {'n_estimators': 100, 'max_depth':12}\n",
    "gbr = RandomForestRegressor(100, max_depth=12).fit(trainX,trainY)\n",
    "print gbr.score(trainX,trainY)\n",
    "prediction = pd.Series(np.floor(gbr.predict(testX)),index=testY.index)\n",
    "prediction[prediction<3]=0\n",
    "evaluate(testY,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.979098134466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9142699088744388"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# params = {'n_estimators': 100, 'max_depth':12}\n",
    "gbr = RandomForestRegressor(200, max_depth=12).fit(trainX,trainY)\n",
    "print gbr.score(trainX,trainY)\n",
    "prediction = pd.Series(np.floor(gbr.predict(testX)),index=testY.index)\n",
    "# prediction[prediction<1]=0\n",
    "evaluate(testY,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: float64)"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[prediction<1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
