{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dateutil.parser import parse as dateutil_parse\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import StandardScaler as skStandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.cross_validation import train_test_split,cross_val_score\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "from mylib import myStandardScaler,process_order,process_traffic,get_order_group,get_traffic_group,XY_order_traffic, prediction2submit, \\\n",
    "    Search_Model, DISTRICTS, request_answer_count, XY_order_cluster\n",
    "\n",
    "PATH = 'season_1/'\n",
    "CLEAN_PATH = PATH+'clean/'\n",
    "SEARCH_PATH = 'clf_rf/'\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_map = pd.read_csv(CLEAN_PATH+'cluster_map.csv',index_col=0)\n",
    "poi = pd.read_csv(CLEAN_PATH+'poi.csv',index_col=0)\n",
    "train_order_group = pd.read_pickle(CLEAN_PATH+'train_order_group.pickle')\n",
    "test_order_group = pd.read_pickle(CLEAN_PATH+'test_order_group.pickle')\n",
    "train_traffic_group = pd.read_pickle(CLEAN_PATH+'train_traffic_group.pickle')\n",
    "test_traffic_group = pd.read_pickle(CLEAN_PATH+'test_traffic_group.pickle')\n",
    "test_target = pd.read_csv(CLEAN_PATH+'test_target.csv',index_col=0,parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_traffic_group.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ra_count = request_answer_count(train_order_group)\n",
    "train_cluster = pd.concat([poi, ra_count], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_range = 8\n",
    "clf = KMeans(n_clusters=label_range, max_iter=100000)\n",
    "s = clf.fit(train_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "district_label = pd.DataFrame({'label':clf.labels_}, index = train_cluster.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_slot = pd.Index(sorted(train_order_group.values()[0].index.unique()))\n",
    "train_slot = pd.Index(filter(lambda x: x%1000 >4,train_slot))\n",
    "test_slot = test_target['datetimeslot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Take 00:00:08\n"
     ]
    }
   ],
   "source": [
    "now = time.time()\n",
    "\n",
    "train_XY_group = dict()\n",
    "for label in range(label_range):\n",
    "    train_XY_group[label] = XY_order_cluster(label, district_label,train_order_group,train_traffic_group,train_slot)\n",
    "    train_XY_group[label][0] = train_XY_group[label][0].sort_index(axis=1)\n",
    "test_XY_group = dict()\n",
    "for district in DISTRICTS:\n",
    "    test_XY_group[district] = XY_order_traffic(district,test_order_group,test_traffic_group,test_slot)\n",
    "    test_XY_group[district][0] = test_XY_group[district][0].sort_index(axis=1)\n",
    "for label in range(label_range):\n",
    "    scaler = myStandardScaler()\n",
    "    train_XY_group[label][0] = scaler.fit_transform(train_XY_group[label][0])\n",
    "    for district in DISTRICTS:\n",
    "        if(district_label.ix[district].values[0] == label and district in train_traffic_group):\n",
    "            Xnumerical = test_XY_group[district][0][test_XY_group[district][0].columns[test_XY_group[district][0].dtypes != bool]]\n",
    "            test_XY_group[district][0] = scaler.transform(test_XY_group[district][0])    \n",
    "stop = time.time()\n",
    "print 'Take %02d:%02d:%02d' % ((stop-now)/3600,(stop-now)/60,(stop-now)%60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 单独处理没有交通信息的那个地点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for district in DISTRICTS:\n",
    "    if district not in train_traffic_group:\n",
    "        train_XY_group[district] = XY_order_traffic(district,train_order_group,train_traffic_group,train_slot)\n",
    "        scaler = myStandardScaler()\n",
    "        train_XY_group[district][0] = scaler.fit_transform(train_XY_group[district][0])\n",
    "        test_XY_group[district][0] = scaler.transform(test_XY_group[district][0])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 'c4ec24e0a58ebedaa1661e5c09e47bb5']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_XY_group.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster + Searcher + Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching c4ec24e0a58ebedaa1661e5c09e47bb5...\n"
     ]
    }
   ],
   "source": [
    "grid_params = {'n_estimators': [80] ,'max_depth': np.arange(10, 18), 'min_samples_leaf': [2, 6], \n",
    "                     'min_samples_split': [2, 6], 'max_features': ['log2', 'sqrt',None]}\n",
    "search_models = {key: Search_Model(RandomForestRegressor) for key in train_XY_group.keys()}\n",
    "test_prediction = dict()\n",
    "for key, model in search_models.items()[::-1]:\n",
    "    if len(os.listdir(SEARCH_PATH))==66:\n",
    "        print 'We can together! :)'\n",
    "        break\n",
    "    if key in DISTRICTS:\n",
    "        now = time.time()\n",
    "        print 'Searching %s...'%key\n",
    "        model.fit(grid_params,*train_XY_group[key])\n",
    "        test_prediction[key] = model.predict(test_XY_group[key][0]) - test_XY_group[key][1].fillna(0)\n",
    "        with open(SEARCH_PATH + 'test_prediction_%s.pickle'%(key),'wb') as f:\n",
    "            pickle.dump(test_prediction[key],f)\n",
    "        stop = time.time()\n",
    "        print 'Take %02d:%02d:%02d' % ((stop-now)/3600,(stop-now)/60,(stop-now)%60)\n",
    "    else:\n",
    "        now = time.time()\n",
    "        print 'Searching cluster %d...'%key\n",
    "        model.fit(grid_params,*train_XY_group[key])\n",
    "        for district in DISTRICTS:\n",
    "            if(district_label.ix[district].values[0] == key): \n",
    "                test_prediction[district] = model.predict(test_XY_group[district][0]) - test_XY_group[district][1].fillna(0)\n",
    "                with open(SEARCH_PATH + 'test_prediction_%s.pickle'%(district),'wb') as f:\n",
    "                    pickle.dump(test_prediction[district],f)\n",
    "        stop = time.time()\n",
    "        print 'Take %02d:%02d:%02d' % ((stop-now)/3600,(stop-now)/60,(stop-now)%60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit = prediction2submit(test_prediction, cluster_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ceil_gap(x):\n",
    "    if(x < 1):\n",
    "        res = 1\n",
    "    else:\n",
    "        res = x\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newgap = submit['prediction'].apply(lambda x: ceil_gap(x))\n",
    "submit['gap'] = newgap\n",
    "submit = submit.drop('prediction', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit.to_csv(PATH+'submit/cluster_searchrf_order_traffic_1.csv',index=None,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
