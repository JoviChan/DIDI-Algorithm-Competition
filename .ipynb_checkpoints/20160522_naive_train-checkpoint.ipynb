{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dateutil.parser import parse as dateutil_parse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler as skStandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.cross_validation import train_test_split,cross_val_score\n",
    "\n",
    "PATH = 'season_1/'\n",
    "CLEAN_PATH = PATH+'clean/'\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class myStandardScaler(skStandardScaler):\n",
    "    '''\n",
    "    Only use fit_transform and tranform, specific for dealing with pd.DataFrame.\n",
    "    Only scale the numerical features.\n",
    "    '''\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        Xnumerical = X[X.columns[X.dtypes != bool]]\n",
    "        Xdummy = X[X.columns[X.dtypes == bool]]\n",
    "        scaledXnumerical = super(myStandardScaler, self).fit_transform(Xnumerical)\n",
    "        Xnumerical = pd.DataFrame(scaledXnumerical, index=Xnumerical.index, columns=Xnumerical.columns)\n",
    "        return pd.concat([Xnumerical, Xdummy], axis=1)\n",
    "\n",
    "    def transform(self, X):\n",
    "        Xnumerical = X[X.columns[X.dtypes != bool]]\n",
    "        Xdummy = X[X.columns[X.dtypes == bool]]\n",
    "        scaledXnumerical = super(myStandardScaler, self).transform(Xnumerical)\n",
    "        Xnumerical = pd.DataFrame(scaledXnumerical, index=Xnumerical.index, columns=Xnumerical.columns)\n",
    "        return pd.concat([Xnumerical, Xdummy], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_map = pd.read_csv(CLEAN_PATH+'cluster_map.csv',index_col=0)\n",
    "poi = pd.read_csv(CLEAN_PATH+'poi.csv',index_col=0)\n",
    "train_order = pd.read_pickle(CLEAN_PATH+'train_order.pickle')\n",
    "test_order = pd.read_pickle(CLEAN_PATH+'test_order.pickle')\n",
    "train_traffic = pd.read_pickle(CLEAN_PATH+'train_traffic.pickle')\n",
    "test_traffic = pd.read_pickle(CLEAN_PATH+'test_traffic.pickle')\n",
    "train_weather = pd.read_pickle(CLEAN_PATH+'train_weather.pickle')\n",
    "test_weather = pd.read_pickle(CLEAN_PATH+'test_weather.pickle')\n",
    "test_target = pd.read_csv(CLEAN_PATH+'test_target.csv',index_col=0,parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_order_index = pd.Series(range(len(train_order)),index=train_order['Time'])\n",
    "test_order_index = pd.Series(range(len(test_order)),index=test_order['Time'])\n",
    "train_traffic_index = pd.Series(range(len(train_traffic)),index=train_traffic['datetime'])\n",
    "test_traffic_index = pd.Series(range(len(test_traffic)),index=test_traffic['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_order(order):\n",
    "    def pclass(p):\n",
    "        class_set = range(5,20,5)+range(20,100,10)+range(100,501,100)\n",
    "        idx_set = [p>cls for cls in class_set]\n",
    "        return idx_set.index(False) if sum(idx_set)!=len(idx_set) else len(idx_set)\n",
    "    order['timeslot'] = order['Time'].map(lambda x: (x.hour*60+x.minute)/10+1)\n",
    "    order['datetimeslot'] = order['Time'].map(lambda x: x.year*10000+x.month*100+x.day)*1000+order['timeslot']\n",
    "    order['pclass'] = order['Price'].map(lambda x: pclass(x))\n",
    "    order = pd.concat([order,pd.get_dummies(order['pclass'],'pclass').applymap(lambda x: {1.0: True, 0.0: False}[x])],axis=1)\n",
    "    return order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_order = process_order(train_order)\n",
    "test_order = process_order(test_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def map_group(group):\n",
    "    res = pd.Series()\n",
    "    res['request'] = group['request'].count()\n",
    "    res['answer'] = group['request'].sum()\n",
    "    res['price_avg'] = group['Price'].mean()\n",
    "    pclass_cols = filter(lambda x: x[:7]=='pclass_',group.columns)\n",
    "    pclass_values = group[pclass_cols].sum()\n",
    "    res = pd.concat([res,pclass_values])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "districts = train_order['start_district_hash'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(districts) == set(test_order['start_district_hash'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_order_group(order):\n",
    "    order_group = dict()\n",
    "    for district in districts:\n",
    "        tmp = order[order['start_district_hash']==district]\n",
    "        order_group[district] = tmp.groupby('datetimeslot').apply(lambda g: map_group(g))      \n",
    "    return order_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_order_group = get_order_group(train_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_order_group = get_order_group(test_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_order(order, dts):\n",
    "    '''\n",
    "    This funciton will not consider the first 3 time slot, for all the days. \n",
    "    It could be changed when test data set changes.\n",
    "    '''\n",
    "    timeslot = pd.get_dummies(dts.map(lambda x: int(x%1000)),'timeslot')\n",
    "    #     target_timeslot = ['timeslot_'+str(i+1) for i in range(144)]\n",
    "    target_timeslot = ['timeslot_'+str(i+1) for i in range(144)]\n",
    "    timeslot = pd.DataFrame(timeslot, columns=target_timeslot).fillna(0)\n",
    "    timeslot.index = dts\n",
    "    timeslot = timeslot.applymap(lambda x: {1.0: True, 0.0: False}[x])\n",
    "    train = pd.concat([order.ix[dts-1].rename(columns=lambda x: '1_'+x,index=lambda x: x+1),\n",
    "                       order.ix[dts-2].rename(columns=lambda x: '2_'+x,index=lambda x: x+2),\n",
    "                       order.ix[dts-3].rename(columns=lambda x: '3_'+x,index=lambda x: x+3),\n",
    "                       timeslot], axis=1)\n",
    "    train = train.dropna()\n",
    "    test = (order['request'].ix[train.index]-order['answer'].ix[train.index])\n",
    "    return [train,test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_XYgroup = dict()\n",
    "for district in train_order_group:\n",
    "    train_XYgroup[district] = train_test_order(train_order_group[district],train_order_group[district].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_XYgroup = dict()\n",
    "for district in test_order_group:\n",
    "    test_XYgroup[district] = train_test_order(test_order_group[district],test_target['datetimeslot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for district in train_order_group:\n",
    "    sample_scaler = myStandardScaler()\n",
    "    train_XYgroup[district][0] = sample_scaler.fit_transform(train_XYgroup[district][0])\n",
    "    test_XYgroup[district][0] = sample_scaler.transform(test_XYgroup[district][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfr_models = {district: RandomForestRegressor(50, max_depth=12) for district in districts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(target, predict):\n",
    "    return ((target-predict).abs()/target).replace(np.inf,0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38d5ad2d22b61109fd8e7b43cd0e8901 r2 score 0.976206929144\n",
      "38d5ad2d22b61109fd8e7b43cd0e8901 metric 0.16656541348\n",
      "08f5b445ec6b29deba62e6fd8b0325a6 r2 score 0.772898555692\n",
      "08f5b445ec6b29deba62e6fd8b0325a6 metric 0.7344593218\n",
      "364bf755f9b270f0f9141d1a61de43ee r2 score 0.852443876634\n",
      "364bf755f9b270f0f9141d1a61de43ee metric 0.360543876501\n",
      "49ac89aa860c27e26c0836cb8dab2df2 r2 score 0.57171773452\n",
      "49ac89aa860c27e26c0836cb8dab2df2 metric 0.868592688746\n",
      "8bb37d24db1ad665e706c2655d9c4c72 r2 score 0.717480497063\n",
      "8bb37d24db1ad665e706c2655d9c4c72 metric 0.417789602114\n",
      "08232402614a9b48895cc3d0aeb0e9f2 r2 score 0.580240614214\n",
      "08232402614a9b48895cc3d0aeb0e9f2 metric 0.901099510105\n",
      "b702e920dcd2765e624dc1ce3a770512 r2 score 0.81876105287\n",
      "b702e920dcd2765e624dc1ce3a770512 metric 0.254310995455\n",
      "52d7b69796362a8ed1691a6cc02ddde4 r2 score 0.478174339602\n",
      "52d7b69796362a8ed1691a6cc02ddde4 metric 0.898683187479\n",
      "62afaf3288e236b389af9cfdc5206415 r2 score 0.96693969669\n",
      "62afaf3288e236b389af9cfdc5206415 metric 0.0617965049884\n",
      "bf44d327f0232325c6d5280926d7b37d r2 score 0.489303507904\n",
      "bf44d327f0232325c6d5280926d7b37d metric 0.96491195262\n",
      "445ff793ebd3477d4a2e0b36b2db9271 r2 score 0.576350899665\n",
      "445ff793ebd3477d4a2e0b36b2db9271 metric 0.961507221268\n",
      "f47f35242ed40655814bc086d7514046 r2 score 0.912192240321\n",
      "f47f35242ed40655814bc086d7514046 metric 0.574104535265\n",
      "c9f855e3e13480aad0af64b418e810c3 r2 score 0.770852809866\n",
      "c9f855e3e13480aad0af64b418e810c3 metric 0.897826056828\n",
      "0a5fef95db34383403d11cb6af937309 r2 score 0.826112498399\n",
      "0a5fef95db34383403d11cb6af937309 metric 0.710246716579\n",
      "ca064c2682ca48c6a21de012e87c0df5 r2 score 0.915492141897\n",
      "ca064c2682ca48c6a21de012e87c0df5 metric 0.215052753959\n",
      "a814069db8d32f0fa6e188f41059c6e1 r2 score 0.437563838768\n",
      "a814069db8d32f0fa6e188f41059c6e1 metric 0.965176182903\n",
      "f9280c5dab6910ed44e518248048b9fe r2 score 0.765053431244\n",
      "f9280c5dab6910ed44e518248048b9fe metric 0.712639017023\n",
      "825c426141df01d38c1b9e9c5330bdac r2 score 0.49431458549\n",
      "825c426141df01d38c1b9e9c5330bdac metric 0.922335192177\n",
      "a5609739c6b5c2719a3752327c5e33a7 r2 score 0.906437894032\n",
      "a5609739c6b5c2719a3752327c5e33a7 metric 0.281032013246\n",
      "2920ece99323b4c111d6f9affc7ea034 r2 score 0.968092090233\n",
      "2920ece99323b4c111d6f9affc7ea034 metric 0.14276394266\n",
      "de092beab9305613aca8f79d7d7224e7 r2 score 0.595840150251\n",
      "de092beab9305613aca8f79d7d7224e7 metric 0.931529109726\n",
      "929ec6c160e6f52c20a4217c7978f681 r2 score 0.966522377083\n",
      "929ec6c160e6f52c20a4217c7978f681 metric 0.0496581944236\n",
      "d524868ce69cb9db10fc5af177fb9423 r2 score 0.737727660297\n",
      "d524868ce69cb9db10fc5af177fb9423 metric 0.931315808489\n",
      "3a43dcdff3c0b66b1acb1644ff055f9d r2 score 0.895337027697\n",
      "3a43dcdff3c0b66b1acb1644ff055f9d metric 0.127469561536\n",
      "1c60154546102e6525f68cb4f31e0657 r2 score 0.524183518955\n",
      "1c60154546102e6525f68cb4f31e0657 metric 0.876328095421\n",
      "2350be163432e42270d2670cb3c02f80 r2 score 0.605880295958\n",
      "2350be163432e42270d2670cb3c02f80 metric 0.628077112686\n",
      "a735449c5c09df639c35a7d61fad3ee5 r2 score 0.82647433556\n",
      "a735449c5c09df639c35a7d61fad3ee5 metric 0.702045384966\n",
      "cb6041cc08444746caf6039d8b9e43cb r2 score 0.63542906089\n",
      "cb6041cc08444746caf6039d8b9e43cb metric 0.848993587347\n",
      "3e12208dd0be281c92a6ab57d9a6fb32 r2 score 0.802989353523\n",
      "3e12208dd0be281c92a6ab57d9a6fb32 metric 0.54261267745\n",
      "4f8d81b5c31af5d1ba579a65ddc8a5cb r2 score 0.88518741897\n",
      "4f8d81b5c31af5d1ba579a65ddc8a5cb metric 0.588581547053\n",
      "52e56004d92b8c74d53e1e42699cba6f r2 score 0.952444889968\n",
      "52e56004d92b8c74d53e1e42699cba6f metric 0.235875889848\n",
      "44c097b7bd219d104050abbafe51bd49 r2 score 0.817805070019\n",
      "44c097b7bd219d104050abbafe51bd49 metric 0.572156315702\n",
      "74ec84f1cf75cf89ae176c8c6ceec5ba r2 score 0.599283890459\n",
      "74ec84f1cf75cf89ae176c8c6ceec5ba metric 0.760730328882\n",
      "ba32abfc048219e933bee869741da911 r2 score 0.520294026322\n",
      "ba32abfc048219e933bee869741da911 metric 0.960595235142\n",
      "74c1c25f4b283fa74a5514307b0d0278 r2 score 0.779847912641\n",
      "74c1c25f4b283fa74a5514307b0d0278 metric 0.154626376677\n",
      "2407d482f0ffa22a947068f2551fe62c r2 score 0.970248447286\n",
      "2407d482f0ffa22a947068f2551fe62c metric 0.117327724458\n",
      "d5cb17978de290c56e84c9cf97e63186 r2 score 0.883013249396\n",
      "d5cb17978de290c56e84c9cf97e63186 metric 0.443884167712\n",
      "4725c39a5e5f4c188d382da3910b3f3f r2 score 0.97135620934\n",
      "4725c39a5e5f4c188d382da3910b3f3f metric 0.0327594618325\n",
      "693a21b16653871bbd455403da5412b4 r2 score 0.841884048463\n",
      "693a21b16653871bbd455403da5412b4 metric 0.356891463841\n",
      "1ecbb52d73c522f184a6fc53128b1ea1 r2 score 0.489570678075\n",
      "1ecbb52d73c522f184a6fc53128b1ea1 metric 0.974997447114\n",
      "8316146a6f78cc6d9f113f0390859417 r2 score 0.697060808745\n",
      "8316146a6f78cc6d9f113f0390859417 metric 0.812750567397\n",
      "87285a66236346350541b8815c5fae94 r2 score 0.830260025396\n",
      "87285a66236346350541b8815c5fae94 metric 0.098098513982\n",
      "58c7a4888306d8ff3a641d1c0feccbe3 r2 score 0.523840294678\n",
      "58c7a4888306d8ff3a641d1c0feccbe3 metric 0.84520211235\n",
      "307afa4120c590b3a46cf4ff5415608a r2 score 0.846796784957\n",
      "307afa4120c590b3a46cf4ff5415608a metric 0.754108209813\n",
      "2301bc920194c95cf0c7486e5675243c r2 score 0.631308729944\n",
      "2301bc920194c95cf0c7486e5675243c metric 0.262285091433\n",
      "b05379ac3f9b7d99370d443cfd5dcc28 r2 score 0.977709821262\n",
      "b05379ac3f9b7d99370d443cfd5dcc28 metric 0.0909185276961\n",
      "fc34648599753c9e74ab238e9a4a07ad r2 score 0.732064724571\n",
      "fc34648599753c9e74ab238e9a4a07ad metric 0.102522396175\n",
      "d4ec2125aff74eded207d2d915ef682f r2 score 0.980927017969\n",
      "d4ec2125aff74eded207d2d915ef682f metric 0.0203927428546\n",
      "825a21aa308dea206adb49c4b77c7805 r2 score 0.437625573867\n",
      "825a21aa308dea206adb49c4b77c7805 metric 0.955177827279\n",
      "c4ec24e0a58ebedaa1661e5c09e47bb5 r2 score 0.479409315899\n",
      "c4ec24e0a58ebedaa1661e5c09e47bb5 metric 0.959053649724\n",
      "73ff8ef735e1d68f0cdcbb84d788f2b6 r2 score 0.646534411708\n",
      "73ff8ef735e1d68f0cdcbb84d788f2b6 metric 0.403062443007\n",
      "1afd7afbc81ecc1b13886a569d869e8a r2 score 0.981711202958\n",
      "1afd7afbc81ecc1b13886a569d869e8a metric 0.133360268044\n",
      "91690261186ae5bee8f83808ea1e4a01 r2 score 0.956324873373\n",
      "91690261186ae5bee8f83808ea1e4a01 metric 0.26213179584\n",
      "82cc4851f9e4faa4e54309f8bb73fd7c r2 score 0.977056798813\n",
      "82cc4851f9e4faa4e54309f8bb73fd7c metric 0.0557365786775\n",
      "dd8d3b9665536d6e05b29c2648c0e69a r2 score 0.762851595845\n",
      "dd8d3b9665536d6e05b29c2648c0e69a metric 0.62935396992\n",
      "f2c8c4bb99e6377d21de71275afd6cd2 r2 score 0.547921883643\n",
      "f2c8c4bb99e6377d21de71275afd6cd2 metric 0.934770095261\n",
      "fff4e8465d1e12621bc361276b6217cf r2 score 0.501095714293\n",
      "fff4e8465d1e12621bc361276b6217cf metric 0.866682660148\n",
      "b26a240205c852804ff8758628c0a86a r2 score 0.952320591704\n",
      "b26a240205c852804ff8758628c0a86a metric 0.137163633362\n",
      "4f4041f7db0c7f69892d9b74c1a7efa1 r2 score 0.775146070124\n",
      "4f4041f7db0c7f69892d9b74c1a7efa1 metric 0.609599348232\n",
      "52a4e8aaa12f70020e889aed8fd5ddbc r2 score 0.879904916216\n",
      "52a4e8aaa12f70020e889aed8fd5ddbc metric 0.22413649098\n",
      "7f84bdfc2b6d4541e1f6c0a3349e0251 r2 score 0.612423094717\n",
      "7f84bdfc2b6d4541e1f6c0a3349e0251 metric 0.917993662993\n",
      "90c5a34f06ac86aee0fd70e2adce7d8a r2 score 0.904133941338\n",
      "90c5a34f06ac86aee0fd70e2adce7d8a metric 0.127149940215\n",
      "1cbfbdd079ef93e74405c53fcfff8567 r2 score 0.943798249278\n",
      "1cbfbdd079ef93e74405c53fcfff8567 metric 0.444834951485\n",
      "4b9e4cf2fbdc8281b8a1f9f12b80ce4d r2 score 0.61067345166\n",
      "4b9e4cf2fbdc8281b8a1f9f12b80ce4d metric 0.787194165819\n",
      "d05052b4bda7662a084f235e880f50fa r2 score 0.801552644321\n",
      "d05052b4bda7662a084f235e880f50fa metric 0.705914646757\n",
      "4b7f6f4e2bf237b6cc58f57142bea5c0 r2 score 0.533412698123\n",
      "4b7f6f4e2bf237b6cc58f57142bea5c0 metric 0.919589281571\n"
     ]
    }
   ],
   "source": [
    "test_prediction = dict()\n",
    "for district, model in rfr_models.items():\n",
    "    model.fit(*train_XYgroup[district])\n",
    "    train_prediction = pd.Series(np.floor(model.predict(train_XYgroup[district][0])),index=train_XYgroup[district][1].index)\n",
    "    test_prediction[district] = np.floor(model.predict(test_XYgroup[district][0])) - test_XYgroup[district][1].fillna(0)\n",
    "    print district,'r2 score', model.score(*train_XYgroup[district])\n",
    "    print district,'metric', evaluate(model.predict(train_XYgroup[district][0]),train_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetimeslot</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20160122046</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160122058</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160122082</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160122118</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160122130</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160122142</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160124070</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160124082</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160124106</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160124118</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160124130</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160124142</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160126058</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160126094</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160126106</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160126118</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160126130</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160128058</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160128070</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160128082</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160128094</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160128106</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160128118</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160130046</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160130058</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160130082</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160130094</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160130106</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160130118</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160130130</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160130142</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              district  prediction\n",
       "datetimeslot                      \n",
       "20160122046          1         5.0\n",
       "20160122058          1         0.0\n",
       "20160122082          1         0.0\n",
       "20160122118          1         0.0\n",
       "20160122130          1         0.0\n",
       "20160122142          1         0.0\n",
       "20160124070          1         0.0\n",
       "20160124082          1         0.0\n",
       "20160124106          1         0.0\n",
       "20160124118          1         0.0\n",
       "20160124130          1         0.0\n",
       "20160124142          1         0.0\n",
       "20160126058          1         0.0\n",
       "20160126094          1         0.0\n",
       "20160126106          1         0.0\n",
       "20160126118          1         0.0\n",
       "20160126130          1         0.0\n",
       "20160128058          1         0.0\n",
       "20160128070          1         0.0\n",
       "20160128082          1         1.0\n",
       "20160128094          1         0.0\n",
       "20160128106          1         0.0\n",
       "20160128118          1         0.0\n",
       "20160130046          1         0.0\n",
       "20160130058          1         0.0\n",
       "20160130082          1         0.0\n",
       "20160130094          1         0.0\n",
       "20160130106          1         0.0\n",
       "20160130118          1         0.0\n",
       "20160130130          1         0.0\n",
       "20160130142          1         0.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'prediction':test_prediction['d524868ce69cb9db10fc5af177fb9423'],'district':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prediction2submit(prediction):\n",
    "    res = []\n",
    "    for district in prediction:\n",
    "        res.append(pd.DataFrame({'prediction':test_prediction[district],'district':district}))\n",
    "    res_1 = pd.concat(res)\n",
    "#     res_1['district'] = res_1['district'].map(lambda x: cluster_map.ix[x,0])\n",
    "    res_2 = pd.DataFrame()\n",
    "    res_2['district'] = res_1['district'].map(lambda x: cluster_map.loc[x,'district_id'])\n",
    "    res_2['dts'] = res_1.index.map(lambda x: '{0}-{1}'.format(dateutil_parse(str(x/1000)).date(),x%1000))\n",
    "    res_2 ['prediction'] = res_1['prediction']\n",
    "    res_2['dts_sort'] = res_2.index\n",
    "    return res_2.sort_values(['dts_sort','district']).drop('dts_sort',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction2submit(test_prediction).to_csv(PATH+'submit/order_rf.csv',header=False,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
